# Gemini by Example

This file contains all examples from the Gemini by Example site (geminibyexample.com).
It's organized by sections, with each example's Python code and terminal commands included.

## Table of Contents

* Text
  * Simple text generation
  * Streaming text
  * System prompt
  * Reasoning models
  * Structured output
* Images
  * Image question answering
  * Image generation (Gemini and Imagen)
  * Edit an image
  * Bounding boxes
  * Image segmentation
* Audio
  * Audio question answering
  * Audio transcription
  * Audio summarization
* Video
  * Video question answering
  * Video summarization
  * Video transcription
  * YouTube video summarization
* PDFs and other data types
  * PDF and CSV data analysis and summarization
  * Translate documents
  * Extract structured data from a PDF
* Agentic behaviour
  * Function calling & tool use

## Text

### Simple text generation

```python
from google import genai
client = genai.Client(api_key="YOUR_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash", contents="Explain how AI works in a few words"
)
print(response.text)
```

```shell
$ pip install google-generative-ai
$ python basic-generation.py
AI works by learning patterns from data, then using those patterns to make predictions or generate new content. It processes information through neural networks that mimic human brain connections, identifying features and relationships to perform tasks like recognition, prediction, and generation.
```

*This example includes images which can be viewed on the website.*

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/text-generation

### Streaming text

This example demonstrates how to use the Gemini API to generate text content and stream the output.

```python
from google import genai
client = genai.Client(api_key="YOUR_API_KEY")
response = client.models.generate_content_stream(
    model="gemini-2.0-flash",
    contents=["Explain how AI works"]
)
for chunk in response:
    print(chunk.text, end="")
```

```shell
$ pip install google-generative-ai
$ python streaming-generation.py
AI, or Artificial Intelligence, is a broad field of computer science focused on creating machines capable of performing tasks that typically require human intelligence. It involves developing algorithms and models that enable computers to learn from data, reason, solve problems, understand natural language, perceive their environment, and make decisions.
AI can be achieved through various techniques, including:
*   **Machine Learning (ML):** This is a core subfield of AI where machines learn from data without being explicitly programmed. ML algorithms can identify patterns, make predictions, and improve their performance over time with more data.
*   **Deep Learning (DL):** A subfield of ML that uses artificial neural networks with multiple layers (deep neural networks) to analyze data and extract complex features. DL has been highly successful in areas like image recognition, natural language processing, and speech recognition.
*   **Natural Language Processing (NLP):** Focuses on enabling computers to understand, interpret, and generate human language. NLP techniques are used in applications like chatbots, machine translation, and sentiment analysis.
*   **Computer Vision:** Enables computers to "see" and interpret images and videos. Computer vision algorithms can identify objects, recognize faces, and analyze scenes.
*   **Robotics:** Involves designing, constructing, operating, and applying robots. AI is often used in robotics to enable robots to perform tasks autonomously.
AI is transforming various industries, including healthcare, finance, transportation, and manufacturing. It has the potential to solve complex problems and improve people's lives, but it also raises ethical and societal concerns that need to be addressed.
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/text-generation

### System prompt

This example demonstrates how to use system instructions to guide the model's behavior.

```python
from google import genai
from google.genai import types
client = genai.Client(api_key="YOUR_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash",
    config=types.GenerateContentConfig(
        system_instruction="You are a pirate.  Answer all questions like a pirate."),
    contents="Hello there"
)
print(response.text)
```

```shell
$ pip install google-generative-ai
$ python system_instructions.py
Ahoy there, matey! What be on yer mind?
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/text-generation#system-instructions

### Reasoning models

This example demonstrates how to access the reasoning trace of a Gemini model
and then the final text output.
Reasoning models are a new type of model that 'think' a little bit before
giving a final answer. The 'thinking' response is visible in Google AI Studio
but not as part of the response to an API call.

```python
from google import genai
import os
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
prompt = "If the universe is expanding, what is it expanding into? Show your reasoning."
response = client.models.generate_content(
    model="gemini-2.5-pro-exp-03-25",
    contents=prompt,
)

print(response.text)
```

```shell
$ pip install google-generative-ai
$ python universe_reasoning.py
This is a fantastic and very common question that gets to the heart of how we understand the universe based on Einstein's theory of General Relativity. The most accurate answer, according to our current understanding, is:
**The universe isn't expanding *into* anything. Space itself is expanding.**
Here's the reasoning:
1.  **General Relativity's View of Spacetime:** Our everyday intuition thinks of space as a pre-existing, static container – like an empty room that things can move around *in*. General Relativity, however, describes spacetime not as a fixed background but as a dynamic entity. It can warp, bend (which we experience as gravity), and, crucially, *expand or contract*.
2.  **Expansion is Intrinsic:** The expansion of the universe isn't like an explosion *within* a pre-existing void, where debris flies outwards *into* empty space. Instead, it's the very fabric of spacetime *itself* that is stretching. Imagine the space *between* galaxies is growing.
3.  **Analogies (and their limitations):**
    *   **The Rising Raisin Bread:** Imagine raisins (representing galaxies) embedded in dough (representing space). As the dough bakes and expands, all the raisins move further apart from each other. A raisin doesn't see itself as being at the center; it sees all other raisins moving away from it. Importantly, the *dough itself* is expanding.
        *   *Limitation:* This analogy breaks down because the dough has edges and is expanding *into* the oven (an external space). Our universe, as far as we know, doesn't have an edge or an "outside."
    *   **The Expanding Balloon Surface:** Imagine drawing dots (galaxies) on the surface of a balloon. As you inflate the balloon, the rubber (space) stretches, and the distance between any two dots on the surface increases. From the perspective of any dot, all other dots are moving away. There is no "center" of expansion *on the surface* itself.
        *   *Limitation:* The 2D surface of the balloon is expanding *into* the 3D space around it. General Relativity doesn't require our 3D space to be expanding into a higher-dimensional "hyperspace." The expansion is an intrinsic property of our spacetime dimensions.
4.  **No Center, No Edge:** Because space *itself* is expanding everywhere, there isn't a central point *from which* the universe is expanding. The Big Bang wasn't an explosion *at* a point *in* space; it was the beginning of the expansion *of* space, happening everywhere simultaneously. Consequently, there's no "edge" of the universe expanding outwards into a void.
5.  **Infinite or Finite?**
    *   If the universe is *infinite*, then it was always infinite. An expanding infinite universe simply becomes "more infinite" – the distances between objects grow, but it isn't expanding *into* anything because there's no outside to an infinite space.
    *   If the universe is *finite* but unbounded (like the surface of the balloon, but in 3D), its total volume increases, but it still doesn't require an external space to expand into. It's self-contained.
**In summary:** The concept of "expanding into" relies on the idea of an external space or container. According to General Relativity, the universe *is* the container (spacetime), and it's this container itself that is growing. There is no need for an "outside" for this expansion to occur.
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/thinking

### Structured output

This example shows how to generate structured data using a pydantic model to represent Cats with name, colour, and special ability.

```python
from google import genai
from pydantic import BaseModel
import os
class Cat(BaseModel):
    name: str
    colour: str
    special_ability: str
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
prompt = "Generate data for 3 cats, including their name, colour and special ability."
response = client.models.generate_content(
    model="gemini-2.0-flash-lite",
    contents=prompt,
    config={
        "response_mime_type": "application/json",
        "response_schema": list[Cat],
    },
)
my_cats: list[Cat] = response.parsed
for cat in my_cats:
    print(
        f"Name: {cat.name}, Colour: {cat.colour}, Special Ability: {cat.special_ability}"
    )
```

```shell
$ pip install google-generative-ai pydantic
$ python structured_cats.py
Name: Aria, Colour: tortoiseshell, Special Ability: Can teleport short distances
Name: Blupus, Colour: ginger, Special Ability: Understands human speech
Name: Moonshine, Colour: black and white, Special Ability: Invisible at night
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/structured-output?lang=python
- https://ai.google.dev/gemini-api/docs/structured-output?lang=rest

## Images

### Image question answering

This example demonstrates how to use the Gemini API to analyze or understand images of cats, including using image URLs and base64 encoding.

```python
from google import genai
from google.genai import types
import requests
import base64
client = genai.Client(api_key="YOUR_API_KEY")
image_url = "https://cataas.com/cat"
image_response = requests.get(image_url)
image_content = image_response.content
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=["What breed of cat is this?", types.Part.from_bytes(data=image_content, mime_type="image/jpeg")]
)

print("Response from URL Image:\n", response.text)
with open("cat.jpg", "rb") as image_file:
    encoded_string = base64.b64encode(image_file.read())
encoded_string = encoded_string.decode('utf-8')
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=["Is this cat fluffy?", types.Part.from_bytes(data=base64.b64decode(encoded_string), mime_type="image/jpeg")]
)

print("\nResponse from Base64 Image:\n", response.text)
```

```shell
$ pip install google-generative-ai requests
$ wget https://cataas.com/cat -O cat.jpg
$ python gemini-cat.py
Response from URL Image:
 This looks like a British Shorthair cat.
Response from Base64 Image:
 Yes, this cat appears to be fluffy.
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/vision?lang=python

### Image generation (Gemini and Imagen)

This example demonstrates generating images using both Gemini 2.0 Flash and Imagen 3 models, focusing on cat-related prompts.

```python
from google import genai
from google.genai import types
from PIL import Image
from io import BytesIO
client = genai.Client(api_key="YOUR_API_KEY")
contents = (
    "Hi, can you create a 3D rendered image of a cat wearing a wizard hat, "
    "casting a spell in a magical forest?"
)

response = client.models.generate_content(
    model="gemini-2.0-flash-exp-image-generation",
    contents=contents,
    config=types.GenerateContentConfig(response_modalities=["Text", "Image"]),
)
for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save("gemini-cat-wizard.png")
        image.show()
response = client.models.generate_images(
    model="imagen-3.0-generate-002",
    prompt="A photorealistic image of a cat astronaut floating in space",
    config=types.GenerateImagesConfig(number_of_images=2),
)
for i, generated_image in enumerate(response.generated_images):
    image = Image.open(BytesIO(generated_image.image.image_bytes))
    image.save(f"imagen-cat-astronaut-{i+1}.png")
    image.show()
```

```shell
$ pip install google-generative-ai Pillow
$ python image-generation.py
# Expected output (will vary based on the model):
# (Text describing the cat wizard image from Gemini 2.0 Flash)
# (Two image windows will open, displaying the generated cat astronaut images from Imagen 3)
# Image saved as gemini-cat-wizard.png
# (Two image windows will open, displaying the generated cat astronaut images from Imagen 3)
```

*This example includes images which can be viewed on the website.*

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/image-generation

### Edit an image

This example demonstrates how to edit an existing image of a cat to add a hat using the Gemini API.

```python
from google import genai
from google.genai import types
from PIL import Image
import requests
from io import BytesIO
import os
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
image_url = "https://cataas.com/cat"
response = requests.get(image_url)
cat_image = Image.open(BytesIO(response.content))
text_prompt = "Please add a stylish top hat to this cat."
model = "gemini-2.0-flash-exp-image-generation"
response = client.models.generate_content(
    model=model,
    contents=[text_prompt, cat_image],
    config=types.GenerateContentConfig(response_modalities=["Text", "Image"]),
)
for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        print(f"Received {part.inline_data.mime_type} data")
image = Image.open(BytesIO(part.inline_data.data))
        image.save("cat_with_hat.png")
        print("\nImage saved as cat_with_hat.png")
```

```shell
$ pip install google-generative-ai Pillow requests
$ python edit_cat.py
Image saved as cat_with_hat.png
```

*This example includes images which can be viewed on the website.*

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/image-generation#gemini-image-editing

### Bounding boxes

This example demonstrates how to use the Gemini API to detect an object (a cat) in an image and retrieve its bounding box coordinates.

```python
from google import genai
import requests
from PIL import Image
from io import BytesIO
client = genai.Client(api_key="YOUR_API_KEY")
prompt = (
    "Return a bounding box for the cat in this image "
    "in [ymin, xmin, ymax, xmax] format."
)
image_url = "https://cataas.com/cat"
response = requests.get(image_url)
cat_image = Image.open(BytesIO(response.content))
response = client.models.generate_content(
    model="gemini-1.5-pro", contents=[cat_image, prompt]
)
print(response.text)
y_min = (200 / 1000) * 800  # 160
x_min = (300 / 1000) * 1000  # 300
y_max = (700 / 1000) * 800  # 560
x_max = (800 / 1000) * 1000  # 800
```

```shell
$ pip install google-generative-ai Pillow requests
$ python object-detection.py
[0.1, 0.2, 0.7, 0.8]
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/vision?lang=python#bbox

### Image segmentation

This example demonstrates how to use the Gemini API to perform image segmentation on a picture of a cat.

```python
from google import genai
import os
import requests
from PIL import Image
from io import BytesIO
import json
import base64
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
prompt = """
Give the segmentation masks for the cat in the image.
Output a JSON list of segmentation masks where each entry contains the 2D
bounding box in the key \"box_2d\", the segmentation mask in key \"mask\", and
the text label in the key \"label\". Use descriptive labels.
"""
image_url = "https://cataas.com/cat"
response = requests.get(image_url)
cat_image = Image.open(BytesIO(response.content))
original_filename = f"cat_original.png"
cat_image.save(original_filename)
print(f"Original image saved as: {original_filename}")
response = client.models.generate_content(
    model="gemini-2.5-pro-exp-03-25", contents=[cat_image, prompt]
)
print(response.text)
response_text = response.text
if "```json" in response_text:
    json_str = response_text.split("```json")[1].split("```")[0].strip()
elif "[" in response_text and "]" in response_text:
    start = response_text.find("[")
    end = response_text.rfind("]") + 1
    json_str = response_text[start:end]
else:
    json_str = response_text
mask_data = json.loads(json_str)
first_mask = mask_data[0]
mask_base64 = first_mask.get("mask", "")
if "base64," in mask_base64:
    mask_base64 = mask_base64.split("base64,")[1]
mask_bytes = base64.b64decode(mask_base64)
mask_image = Image.open(BytesIO(mask_bytes))
cat_image = cat_image.convert("RGBA")
mask_image = mask_image.convert("L")  # Convert mask to grayscale
overlay = Image.new(
    "RGBA", mask_image.size, (255, 0, 255, 128)
)  # Bright pink, semi-transparent
overlay.putalpha(mask_image)
if overlay.size != cat_image.size:
    overlay = overlay.resize(cat_image.size)
result = Image.alpha_composite(cat_image, overlay)

mask_filename = f"cat_mask.png"
mask_image.save(mask_filename)

merged_filename = f"cat_with_mask.png"
result.save(merged_filename)
```

```shell
$ pip install google-generative-ai
$ python cat_segmentation.py
# Expected output (example):
# [{"box_2d": [100, 50, 900, 750], "mask": "base64_encoded_png_data", "label": "Main Coon Cat"}, ...]
```

*This example includes images which can be viewed on the website.*

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/vision?lang=python#image_segmentation

## Audio

### Audio question answering

This example demonstrates how to ask a question about the content of an audio file using the Gemini API.

```python
from google import genai
from google.genai import types
import requests
import os
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
user_agent = "GeminiByExample/1.0 (https://github.com/strickvl/geminibyexample; contact@example.org) python-requests/2.0"
url = "https://upload.wikimedia.org/wikipedia/commons/1/1f/%22DayBreak%22_with_Jay_Young_on_the_USA_Radio_Network.ogg"
headers = {"User-Agent": user_agent}
response = requests.get(url, headers=headers)
response.raise_for_status()  # Raise an exception for bad status codes
audio_bytes = response.content
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[
        "What is the main topic of this audio?",
        types.Part.from_bytes(
            data=audio_bytes,
            mime_type="audio/ogg",
        ),
    ],
)

print(response.text)
```

```shell
$ pip install google-generative-ai requests
$ python audio-question.py
This audio features a male host and a travel expert, Pete Trabucco.
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/audio?lang=python

### Audio transcription

This example demonstrates how to transcribe an audio file by providing the audio data inline with the request.

```python
from google import genai
from google.genai import types
import requests
client = genai.Client(api_key="YOUR_API_KEY")
user_agent = "GeminiByExample/1.0 (https://github.com/strickvl/geminibyexample; contact@example.org) python-requests/2.0"
url = "https://upload.wikimedia.org/wikipedia/commons/1/1f/%22DayBreak%22_with_Jay_Young_on_the_USA_Radio_Network.ogg"
headers = {"User-Agent": user_agent}
response = requests.get(url, headers=headers)
response.raise_for_status()  # Raise an exception for bad status codes
audio_bytes = response.content
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[
        "Transcribe this audio clip",
        types.Part.from_bytes(
            data=audio_bytes,
            mime_type="audio/ogg",
        ),
    ],
)
print(response.text)
```

```shell
$ pip install google-generative-ai
$ python audio-transcription.py
We're joined once again by our travel expert and also author of America's Top Roller Coasters and Amusement Parks, Pete Trabucco. Good morning and welcome back to Daybreak USA. Well, thanks for having me on. If someone's lucky enough to go on vacation to an exotic location, and then maybe not so lucky to have some kind of a disaster happen while they're there, maybe some civil unrest. What should they do now? What's the next step? Well, whenever you're going on vacation whether it's locally or internationally, you've got to be uh very careful.
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/audio?lang=python

### Audio summarization

This example demonstrates how to summarize the content of an audio file using the Gemini API.

```python
from google import genai
from google.genai import types
import requests
import os
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
user_agent = "GeminiByExample/1.0 (https://github.com/strickvl/geminibyexample; contact@example.org) python-requests/2.0"
url = "https://upload.wikimedia.org/wikipedia/commons/1/1f/%22DayBreak%22_with_Jay_Young_on_the_USA_Radio_Network.ogg"
headers = {"User-Agent": user_agent}
response = requests.get(url, headers=headers)
response.raise_for_status()  # Raise an exception for bad status codes
audio_bytes = response.content
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[
        "What is this audio about?",
        types.Part.from_bytes(
            data=audio_bytes,
            mime_type="audio/ogg",
        ),
    ],
)

print(response.text)
```

```shell
$ pip install google-generative-ai requests
$ python audio-summarization.py
This audio is about travel tips, particularly what to do in the event of a disaster while on vacation.
The speaker emphasizes the importance of staying informed about the destination, traveling with a buddy,
having a plan in place, and investing in travel insurance. They also mention the importance of connecting
with home base and knowing the location of the American Red Cross in case of emergencies.
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/audio?lang=python

## Video

### Video question answering

This example demonstrates how to ask questions about a video using the Gemini API.
Note: For videos larger than 20MB, you must use the File API for uploading.

```python
from google import genai
from google.genai import types
import os
import requests
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

video_url = "https://download.samplelib.com/mp4/sample-5s.mp4"
response = requests.get(video_url)
video_bytes = response.content
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(text="Describe the tone and genre of this video."),
            types.Part(inline_data=types.Blob(data=video_bytes, mime_type="video/mp4")),
        ]
    ),
)
print(response.text)
```

```shell
$ pip install google-generative-ai
$ python video_question_answering.py
Certainly! Here's a description of the tone and genre of the video clip:
**Genre:**  Travel or scenery/ambient video
**Tone:** Relaxed, peaceful, and observational. The video presents a serene view of a park next to a busy street. The presence of nature with the sounds of the city creates a tranquil atmosphere.
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

### Video summarization

This example demonstrates how to summarize the content of a video using the Gemini API.
Note: For videos larger than 20MB, you must use the File API for uploading.

```python
from google import genai
from google.genai import types
import os
import requests
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

video_url = "https://download.samplelib.com/mp4/sample-5s.mp4"
response = requests.get(video_url)
video_bytes = response.content
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(text="Summarize the content of this video."),
            types.Part(inline_data=types.Blob(data=video_bytes, mime_type="video/mp4")),
        ]
    ),
)
print(response.text)
```

```shell
$ pip install google-generative-ai
$ python video_summarization.py
The video shows a park with trees next to a busy street with cars and buses passing by. The sun shines through the leaves of the trees.
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

### Video transcription

This example demonstrates how to transcribe the content of a video using the Gemini API.
Note: For videos larger than 20MB, you must use the File API for uploading.

```python
from google import genai
from google.genai import types
import os
import requests
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

video_url = "https://download.samplelib.com/mp4/sample-5s.mp4"
response = requests.get(video_url)
video_bytes = response.content
prompt = (
    "Transcribe the audio from this video, giving timestamps for "
    "salient events in the video. Also provide visual descriptions."
)
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=types.Content(
        parts=[
            types.Part(text=prompt),
            types.Part(inline_data=types.Blob(data=video_bytes, mime_type="video/mp4")),
        ]
    ),
)
print(response.text)
```

```shell
$ pip install google-generative-ai
$ python video_transcription.py
Okay, here's the transcription and visual descriptions of the video:
**Video Description:**
The video pans up from a low angle showing a park with lush green trees.  Sunlight filters through the leaves. In the distance, cars and a bus can be seen on a road next to the park. There is a paved walkway and low bushes.
**Timestamps:**
*   **0:00** Camera starts panning up showing a park with trees and sunlight. 
*   **0:04** The camera reaches its highest point in its view.
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

### YouTube video summarization

This example demonstrates how to summarize a YouTube video using its URL.

```python
from google import genai
client = genai.Client(api_key="YOUR_API_KEY")
youtube_url = "https://www.youtube.com/watch?v=tAP1eZYEuKA"
prompt = f"Summarize the content of this YouTube video: {youtube_url}"
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[
        {
            "parts": [
                {"text": "Can you summarize this video?"},
                {"file_data": {"file_uri": youtube_url}},
            ]
        }
    ],
)
print(response.text)
```

```shell
$ pip install google-generative-ai
$ python youtube-summarization.py
Sure, here is a summary of the video!
Thomas, the father, is sharing his son Max's story of having Alexander Disease, a rare ultra-rare genetic disorder. After having a difficult time conceiving and finally being successful and welcoming Max to their family, they were dealt a devastating blow when Max had his first seizure at a very young age. 
Because of the seizure, Max had to go through a series of medical tests. Those tests showed that Max had Alexander Disease. After doing some research, the family was heartbroken, as the typical life expectancy for this disease is 5-10 years, and there is no treatment or cure.
Thomas started researching more in-depth by summarizing scientific papers by using Gemini AI and has discovered a lead scientist and her team in New York that he connected with. He sends one to two emails a week to different scientists in order to get more studies underway for the disease. He doesn't want Max to be seen as having 'zero' chance and wants to be a dad and enjoy his time with Max. He will continue to strive to find a cure for Max!
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/vision?lang=python#youtube

## PDFs and other data types

### PDF and CSV data analysis and summarization

This example demonstrates how to use the Gemini API to analyze data from PDF and CSV files.

```python
from google import genai
from google.genai import types
import httpx
import os
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
pdf_url = "https://www.princexml.com/samples/invoice/invoicesample.pdf"
pdf_data = httpx.get(pdf_url).content
pdf_prompt = (
    "Identify the main companies or entities mentioned in this invoice. "
    "Summarize the data."
)
pdf_response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[
        types.Part.from_bytes(data=pdf_data, mime_type="application/pdf"),
        pdf_prompt,
    ],
)
print("PDF Analysis Result:\n", pdf_response.text)
csv_url = "https://gist.githubusercontent.com/suellenstringer-hye/f2231b3383538bcb1a5b051c7908f5b7/raw/0f4e0733a434733cda8e749bbbf33a93c2b5bbde/test.csv"
csv_data = httpx.get(csv_url).content
csv_prompt = "Analyze this data and tell me about the contents. Summarize the data."
csv_response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[
        types.Part.from_bytes(
            data=csv_data,
            mime_type="text/csv",
        ),
        csv_prompt,
    ],
)
print("\nCSV Analysis Result:\n", csv_response.text)
```

```shell
$ pip install google-generative-ai httpx pandas
$ python pdf_csv_analysis.py
PDF Analysis Result:
 The main company mentioned in the invoice is Sunny Farm.
CSV Analysis Result:
 Okay, I've analyzed the provided data. Here's a summary of its contents:
**Data Format:**
*   The data appears to be in CSV (Comma Separated Values) format.
*   The first line is a header row defining the fields.
*   Each subsequent line represents a record containing information about a person.
**Fields Present:**
The data includes the following fields for each person:
1.  **first\_name:** The person's first name.
2.  **last\_name:** The person's last name.
3.  **company\_name:** The name of the company they are associated with.
4.  **address:** The street address.
5.  **city:** The city.
6.  **county:** The county.
7.  **state:** The state.
8.  **zip:** The zip code.
9.  **phone1:** The primary phone number.
10. **phone2:** A secondary phone number.
11. **email:** The email address.
12. **web:** The website address (presumably for the associated company).
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/document-processing?lang=python
- https://ai.google.dev/gemini-api/docs/document-processing?lang=rest

### Translate documents

This example demonstrates how to load content from a URL and translate it into
Chinese using the Gemini API.
It's easy to do the same using PDF or Markdown files, though you might want to
split it up into smaller chunks for better accuracy if your document is long.

```python
from google import genai
import requests
import os
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
url = "https://raw.githubusercontent.com/zenml-io/zenml/refs/heads/main/README.md"
response = requests.get(url)
text_content = response.text
prompt = f"Translate the following English text to Chinese: {text_content}"
model = client.models.generate_content(
    model="gemini-2.0-flash-lite",
    contents=prompt,
)
print(model.text)
```

```shell
$ pip install google-generative-ai requests
$ python translate.py
```chinese
<div align="center">
  <img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=0fcbab94-8fbe-4a38-93e8-c2348450a42e" />
  <h1 align="center">超越演示：生产级 AI 系统</h1>
  <h3 align="center">ZenML 将经过实战检验的 MLOps 实践带入您的 AI 应用，处理大规模的评估、监控和部署</h3>
</div>
<!-- 项目徽章 -->
<!--
*** 我使用 Markdown "引用样式" 链接以提高可读性。
*** 引用链接用方括号 [ ] 括起来，而不是用括号 ( )。
*** 请参阅本文档底部，了解贡献者网址、分支网址等的引用变量声明。 这是一个可选的、简洁的语法，您可以使用它。
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->
<div align="center">
  <!-- 项目 Logo -->
  <br />
    <a href="https://zenml.io">
      <img alt="ZenML Logo" src="docs/book/.gitbook/assets/header.png" alt="ZenML Logo">
    </a>
  <br />
etc...
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/document-processing?lang=python
- https://ai.google.dev/gemini-api/docs/document-processing?lang=rest

### Extract structured data from a PDF

This example demonstrates how to extract structured data from a PDF invoice using the Gemini API and Pydantic.

```python
import os
import requests
import json
import re
from pydantic import BaseModel, Field
from typing import List, Union
from google import genai
from google.genai import types
class Item(BaseModel):
    name: str
    price_per_kg: Union[float, str] = Field(..., alias="price/kg")
    quantity_kg: Union[float, int] = Field(..., alias="quantity (kg)")


class InvoiceContents(BaseModel):
    sender: str
    recipient: str
    address: str
    full_total: Union[float, str]
    subtotal: Union[float, str]
    gst_value: Union[float, str] = Field(..., alias="GST")
    items: List[Item]
pdf_url = "https://www.princexml.com/samples/invoice/invoicesample.pdf"
response = requests.get(pdf_url)
response.raise_for_status()  # Ensure the download was successful
pdf_data = response.content
client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY", "YOUR_API_KEY"))
model = "gemini-2.5-pro-preview-03-25"
prompt_text = (
    "Extract the following information from the invoice: "
    "sender, recipient, address, full_total, subtotal, GST, "
    "and a list of items (name, price/kg, quantity (kg))."
)
response = client.models.generate_content(
    model=model,
    contents=[
        types.Part.from_bytes(data=pdf_data, mime_type="application/pdf"),
        prompt_text,
    ],
    config=genai.types.GenerateContentConfig(temperature=0.0),
)
response_text = response.text
json_match = re.search(r"```(?:json)?\n(.*?)```", response_text, re.DOTALL)
if json_match:
    json_str = json_match.group(1).strip()
else:
    json_str = response_text.strip()
invoice_data = json.loads(json_str)
invoice = InvoiceContents(**invoice_data)
print(invoice.model_dump_json(indent=2))
```

```shell
$ pip install google-generative-ai pydantic requests
$ python structured-data-extraction.py
{
  "sender": "SUNNY FARM",
  "recipient": "Denny Gunawan",
  "address": "221 Queen St\nMelbourne VIC 3000",
  "full_total": "$39.60",
  "subtotal": "$36.00",
  "gst_value": "$3.60",
  "items": [
    {
      "name": "Apple",
      "price_per_kg": "$5.00",
      "quantity_kg": 1
    },
    {
      "name": "Orange",
      "price_per_kg": "$1.99",
      "quantity_kg": 2
    },
    {
      "name": "Watermelon",
      "price_per_kg": "$1.69",
      "quantity_kg": 3
    },
    {
      "name": "Mango",
      "price_per_kg": "$9.56",
      "quantity_kg": 2
    },
    {
      "name": "Peach",
      "price_per_kg": "$2.99",
      "quantity_kg": 1
    }
  ]
}
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/document-processing
- https://ai.google.dev/gemini-api/docs/structured-output?lang=python

## Agentic behaviour

### Function calling & tool use

This example demonstrates how to use the Gemini API to call external functions.

```python
import os
from datetime import datetime
from google import genai
from google.genai import types
def get_current_temperature(location: str) -> dict:
    """Gets the current temperature for a given location.

    Note: This is a simplified mock implementation. In a real application,
    this function would make an API call to a weather service provider.
    """
    sample_temperatures = {
        "London": 16,
        "New York": 23,
        "Tokyo": 28,
        "Sydney": 20,
        "Paris": 18,
        "Berlin": 17,
        "Cairo": 32,
        "Moscow": 10,
    }
    temp = sample_temperatures.get(location, 21)
    return {"location": location, "temperature": temp, "unit": "Celsius"}
def check_appointment_availability(date: str, time: str) -> dict:
    """Checks if there's availability for an appointment at the given date and time."""
    busy_slots = [
        {"date": "2024-07-04", "times": ["14:00", "15:00", "16:00"]},
        {"date": "2024-07-05", "times": ["09:00", "10:00", "11:00"]},
        {"date": "2024-07-10", "times": ["13:00", "14:00"]},
    ]

    try:
        datetime.strptime(date, "%Y-%m-%d")
    except ValueError:
        return {
            "available": False,
            "error": "Invalid date format. Please use YYYY-MM-DD.",
        }

    try:
        datetime.strptime(time, "%H:%M")
    except ValueError:
        return {
            "available": False,
            "error": "Invalid time format. Please use HH:MM in 24-hour format.",
        }

    for slot in busy_slots:
        if slot["date"] == date and time in slot["times"]:
            return {
                "available": False,
                "message": f"The slot on {date} at {time} is already booked.",
            }

    return {
        "available": True,
        "message": f"The slot on {date} at {time} is available for booking.",
    }
print("\n--- Example 1: Basic Function Calling ---\n")
weather_function = {
    "name": "get_current_temperature",
    "description": "Gets the current temperature for a given location.",
    "parameters": {
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "The city name, e.g. San Francisco",
            },
        },
        "required": ["location"],
    },
}
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
tools = types.Tool(function_declarations=[weather_function])
config = types.GenerateContentConfig(tools=[tools])
response = client.models.generate_content(
    model="gemini-2.0-flash-lite",
    contents="What's the temperature in London?",
    config=config,
)
function_call = response.candidates[0].content.parts[0].function_call
print(f"Function to call: {function_call.name}")
print(f"Arguments: {function_call.args}")
result = get_current_temperature(**function_call.args)
print(f"Function result: {result}")
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[
        {
            "parts": [
                {
                    "function_response": {
                        "name": function_call.name,
                        "response": result,
                    }
                }
            ]
        }
    ],
)
print(f"Model's final response: {response.text}")
print("\n--- Example 2: Parallel Function Calling (Weather and Appointments) ---\n")
weather_function = {
    "name": "get_current_temperature",
    "description": "Gets the current temperature for a given location.",
    "parameters": {
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "The city name, e.g. London",
            },
        },
        "required": ["location"],
    },
}
appointment_function = {
    "name": "check_appointment_availability",
    "description": "Checks if there's availability for an appointment at the given date and time.",
    "parameters": {
        "type": "object",
        "properties": {
            "date": {
                "type": "string",
                "description": "Date to check (YYYY-MM-DD)",
            },
            "time": {
                "type": "string",
                "description": "Time to check (HH:MM) in 24-hour format",
            },
        },
        "required": ["date", "time"],
    },
}
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
tools = [types.Tool(function_declarations=[weather_function, appointment_function])]
config = {
    "tools": tools,
    "temperature": 0.1,
}
chat = client.chats.create(model="gemini-2.0-flash-lite", config=config)
response = chat.send_message(
    "I'm planning to visit Paris on July 4th at 2 PM. What's the weather like there and is that slot available for an appointment?"
)
results = {}
for fn in response.function_calls:
    args_str = ", ".join(f"{key}={val}" for key, val in fn.args.items())
    print(f"{fn.name}({args_str})")
if fn.name == "get_current_temperature":
        result = get_current_temperature(**fn.args)
    elif fn.name == "check_appointment_availability":
        result = check_appointment_availability(**fn.args)
    else:
        result = {"error": f"Unknown function: {fn.name}"}
results[fn.name] = result
    print(f"Result: {result}\n")
function_responses = []
for fn_name, result in results.items():
    function_responses.append({"name": fn_name, "response": result})
if function_responses:
    print("Sending all function results back to the model...\n")
    response = chat.send_message(str(function_responses))
    print(f"Model's final response:\n{response.text}")
```

```shell
$ pip install google-generative-ai requests
$ python function_calling_weather_calendar.py
--- Example 1: Basic Function Calling ---
Function to call: get_current_temperature
Arguments: {'location': 'London'}
Function result: {'location': 'London', 'temperature': 16, 'unit': 'Celsius'}
Model's final response: OK. The current temperature in London is 16 degrees Celsius.
--- Example 2: Parallel Function Calling (Weather and Appointments) ---
get_current_temperature(location=Paris)
Result: {'location': 'Paris', 'temperature': 18, 'unit': 'Celsius'}
check_appointment_availability(time=14:00, date=2024-07-04)
Result: {'available': False, 'message': 'The slot on 2024-07-04 at 14:00 is already booked.'}
Sending all function results back to the model...
Model's final response:
The current temperature in Paris is 18 degrees Celsius. The appointment slot on July 4th at 2 PM is not available.
```

For more information, see the original documentation:
- https://ai.google.dev/gemini-api/docs/function-calling?example=weather
- https://ai.google.dev/gemini-api/docs/function-calling?example=meeting

